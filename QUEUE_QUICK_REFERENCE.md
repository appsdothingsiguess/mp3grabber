# Job Queue Quick Reference Guide

## Quick Start

The queue system is **automatic** - no configuration needed. Just start the server and it works!

```bash
npm start
```

## How It Works

### ğŸ¯ One Job at a Time
- Only **1 download/transcription** processes at a time
- All other jobs wait in queue
- Sequential processing prevents server crashes

### ğŸ” Automatic Deduplication
- **Kaltura URLs**: Deduplicated by `entryId` (e.g., `1_abc123xyz`)
- **Regular URLs**: Deduplicated by full URL
- **Duplicates**: Automatically skipped with log message

### ğŸ“Š Three-Level Duplicate Check
1. **Currently Processing**: Is this job running right now?
2. **In Queue**: Is this job waiting to be processed?
3. **Completed**: Was this job already done in this session?

## Log Messages Explained

### Queue Operations
```
ğŸ“¥ [QUEUE] Added job abc-123 (entryId: 1_xyz789) - Queue size: 3
â””â”€ Job added to queue, 3 total jobs waiting

ğŸš€ [QUEUE] Processing job abc-123 - Remaining: 2
â””â”€ Job started, 2 jobs still waiting

âœ… [QUEUE] Job abc-123 completed
â””â”€ Job finished successfully

âŒ [QUEUE] Job abc-123 failed: error message
â””â”€ Job failed but queue continues

ğŸ“‹ [QUEUE] 2 job(s) remaining
â””â”€ Status update between jobs

âœ¨ [QUEUE] All jobs completed
â””â”€ Queue is empty, all done!
```

### Deduplication
```
â­ï¸  [SKIP] Duplicate stream detected: 1_xyz789
â””â”€ This video is already queued/processing/completed
```

### Download Progress
```
ğŸ¬ [DOWNLOAD] Starting download for job abc-123
â””â”€ Download phase started

ğŸ“¥ [DOWNLOAD] Starting yt-dlp download...
â””â”€ yt-dlp process spawned

âœ… [DOWNLOAD] Download complete for job abc-123
â””â”€ File downloaded successfully

ğŸ“„ [DOWNLOAD] File saved: abc-123.mp4
â””â”€ File saved with this name
```

### Transcription Progress
```
ğŸ™ï¸  [TRANSCRIBE] Starting transcription for job abc-123...
â””â”€ Whisper model loading

âœ… [TRANSCRIBE] Transcription complete for job abc-123
â””â”€ Transcription finished successfully
```

## Monitor Queue Status

### REST API
```bash
curl http://localhost:8787/queue/status
```

### Response
```json
{
  "queueSize": 3,           // Jobs waiting
  "processing": true,       // Is a job running?
  "currentJob": "abc-123",  // Job ID currently processing
  "completedCount": 5       // Total completed this session
}
```

## Example Scenarios

### Scenario 1: Normal Operation
```
User requests video â†’ Added to queue â†’ Processes â†’ Completes
ğŸ“¥ â†’ ğŸš€ â†’ ğŸ¬ â†’ ğŸ“¥ â†’ âœ… â†’ ğŸ™ï¸ â†’ âœ…
```

### Scenario 2: Duplicate Detected
```
User requests same video again â†’ Skipped
â­ï¸  [SKIP] Duplicate stream detected
```

### Scenario 3: Multiple Jobs
```
Request A â†’ Added (position 1)
Request B â†’ Added (position 2)
Request C â†’ Added (position 3)

Processing: A â†’ B â†’ C (one at a time)
```

### Scenario 4: Kaltura Multi-URL
```
Extension detects:
- Master manifest: /entryId/1_abc123/...master
- 720p variant:    /entryId/1_abc123/...720p
- 480p variant:    /entryId/1_abc123/...480p

Result: Only FIRST one is processed, others skipped (same entryId)
```

## Troubleshooting

### Problem: Queue seems stuck
**Check**: Look for `ğŸš€ [QUEUE] Processing job` in logs
- If present: Job is running, wait for completion
- If absent: Check for errors in logs

### Problem: All jobs getting skipped
**Reason**: Videos already completed in this session
**Solution**: Restart server to clear `completedIds`

### Problem: Want to process same video again
**Solution**: Restart the server - completed IDs are session-based

### Problem: Too many jobs waiting
**Check**: Queue status endpoint to see queue size
**Note**: This is expected behavior - jobs process sequentially

## Technical Details

### EntryId Extraction
```javascript
// Kaltura URL pattern
/entryId/([^\/]+)/

// Examples
/entryId/1_abc123/     â†’ ID: 1_abc123
/entryId/0_xyz789/     â†’ ID: 0_xyz789
https://example.com/   â†’ ID: full URL
```

### File Naming
All downloads forced to: `[jobId].mp4`
- Example: `abc-123-def-456.mp4`
- Prevents naming conflicts
- Easy to track

### yt-dlp Arguments
```bash
--cookies [file]              # Session auth
-f best                       # Best quality
--downloader ffmpeg           # Fix HLS issues âœ…
--hls-use-mpegts             # Fix HLS warnings âœ…
--postprocessor-args ...     # Fix timestamps
-o [path]                    # Force filename
```

## Best Practices

### âœ… DO
- Let the system handle deduplication automatically
- Monitor queue status during heavy loads
- Check logs for `[SKIP]` messages to see what's being filtered
- Use the status endpoint for monitoring

### âŒ DON'T
- Don't manually try to process same video multiple times
- Don't worry about multiple URLs - system handles it
- Don't restart server unnecessarily (loses completed IDs)
- Don't modify queue system unless you understand it

## Performance

### Expected Behavior
- **1st job**: Starts immediately
- **2nd+ jobs**: Wait in queue
- **Duplicates**: Instant skip (no processing)

### Typical Timeline
```
Download:      30s - 5min (depends on video size)
Transcription: 1min - 10min (depends on length & GPU/CPU)
Total:         2min - 15min per video
```

### Memory Usage
- `completedIds` Set grows with unique videos
- Typical session: < 1000 videos = negligible memory
- Long-running: Consider periodic restarts

## WebSocket Messages

### Client Receives

#### Job Queued
```json
{
  "type": "transcription_queued",
  "payload": {
    "id": "abc-123",
    "queuePosition": 3
  }
}
```

#### Job Skipped (Duplicate)
```json
{
  "type": "transcription_skipped",
  "payload": {
    "id": "abc-123",
    "reason": "Duplicate stream detected",
    "url": "https://..."
  }
}
```

#### Job Complete
```json
{
  "type": "transcription_done",
  "payload": {
    "id": "abc-123",
    "transcript": "...",
    "source": "sniffer"
  }
}
```

#### Job Failed
```json
{
  "type": "transcription_failed",
  "payload": {
    "id": "abc-123",
    "error": "Error message"
  }
}
```

## Summary

âœ… **Automatic**: No configuration needed  
âœ… **Safe**: One job at a time prevents crashes  
âœ… **Smart**: Deduplicates by entryId or URL  
âœ… **Reliable**: HLS streams work properly  
âœ… **Monitored**: Clear logs and status endpoint  

---

**Need Help?**
- Check logs for `[QUEUE]`, `[SKIP]`, `[DOWNLOAD]`, `[TRANSCRIBE]` messages
- Use status endpoint: `GET /queue/status`
- Look at completed test: `node test_queue.js`
- Read full documentation: `QUEUE_IMPLEMENTATION_SUMMARY.md`
